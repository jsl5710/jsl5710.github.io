@inproceedings{lucas-etal-2022-detecting,
    title = "\textbf{Detecting False Claims in Low-Resource Regions: A Case Study of {C}aribbean Islands}",
    author = "\textbf{Lucas, Jason}  and
      Cui, Limeng  and
      Le, Thai  and
      Lee, Dongwon",
    editor = "Chakraborty, Tanmoy  and
      Akhtar, Md. Shad  and
      Shu, Kai  and
      Bernard, H. Russell  and
      Liakata, Maria  and
      Nakov, Preslav  and
      Srivastava, Aseem",
    booktitle = "Proceedings of the Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situations",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "\textbf{Association for Computational Linguistics}",
    url = "https://aclanthology.org/2022.constraint-1.11",
    doi = "10.18653/v1/2022.constraint-1.11",
    pages = "95--102",
    abstract = "The COVID-19 pandemic has created threats to global health control. Misinformation circulated on social media and news outlets has undermined public trust towards Government and health agencies. This problem is further exacerbated in developing countries or low-resource regions, where the news is not equipped with abundant English fact-checking information. In this paper, we make the first attempt to detect COVID-19 misinformation (in English, Spanish, and Haitian French) populated in the Caribbean regions, using the fact-checked claims in the US (in English). We started by collecting a dataset of Caribbean real {\&} fake claims. Then we trained several classification and language models on COVID-19 in the high-resource language regions and transferred the knowledge to the Caribbean claim dataset. The experimental results of this paper reveal the limitations of current fake claim detection in low-resource regions and encourage further research on multi-lingual detection.",
}

@inproceedings{lucas-etal-2023-fighting,
    title = "\textbf{Fighting Fire with Fire: The Dual Role of {LLM}s in Crafting and Detecting Elusive Disinformation}",
    author = "\textbf{Lucas, Jason}  and
      Uchendu, Adaku  and
      Yamashita, Michiharu  and
      Lee, Jooyoung  and
      Rohatgi, Shaurya  and
      Lee, Dongwon",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "\textbf{Association for Computational Linguistics}",
    url = "https://aclanthology.org/2023.emnlp-main.883",
    pages = "14279--14305",
    abstract = "Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (*.i.e, generating large-scale harmful and misleading content*). To combat this emerging risk of LLMs, we propose a novel {``}***Fighting Fire with Fire***{''} (F3) strategy that harnesses modern LLMs{'} generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation. First, we leverage GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content through paraphrase-based and perturbation-based prefix-style prompts, respectively. Second, we apply zero-shot in-context semantic reasoning techniques with cloze-style prompts to discern genuine from deceptive posts and news articles. In our extensive experiments, we observe GPT-3.5-turbo{'}s zero-shot superiority for both in-distribution and out-of-distribution datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72{\%}, unlike the decline observed in previous customized and fine-tuned disinformation detectors. Our codebase and dataset are available at https://github.com/mickeymst/F3.",
}


@inproceedings{macko-etal-2023-multitude,
    title = "\textbf{{MULTIT}u{DE}: Large-Scale Multilingual Machine-Generated Text Detection Benchmark}",
    author = "Macko, Dominik  and
      Moro, Robert  and
      Uchendu, Adaku  and
      \textbf{Lucas, Jason}  and
      Yamashita, Michiharu  and
      Pikuliak, Mat{\'u}{\v{s}}  and
      Srba, Ivan  and
      Le, Thai  and
      Lee, Dongwon  and
      Simko, Jakub  and
      Bielikova, Maria",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "\textbf{Association for Computational Linguistics}",
    url = "https://aclanthology.org/2023.emnlp-main.616",
    pages = "9960--9987",
    abstract = "There is a lack of research into capabilities of recent LLMs to generate convincing text in languages other than English and into performance of detectors of machine-generated text in multilingual settings. This is also reflected in the available benchmarks which lack authentic texts in languages other than English and predominantly cover older generators. To fill this gap, we introduce MULTITuDE, a novel benchmarking dataset for multilingual machine-generated text detection comprising of 74,081 authentic and machine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru, uk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we compare the performance of zero-shot (statistical and black-box) and fine-tuned detectors. Considering the multilinguality, we evaluate 1) how these detectors generalize to unseen languages (linguistically similar as well as dissimilar) and unseen LLMs and 2) whether the detectors improve their performance when trained on multiple languages.",
}
